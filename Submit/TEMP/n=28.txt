Here, let's take o(n!) as algorithm complexity, now , time taken for runnig algorithm is as follows for 16 processors:-
16 - 0.65
17 - 5
18 - 34
19 - 265
20 - 2042 

now let's take maximum speedup 16 for all and flops per second = 1e10.
so total flops per second = 16e10
now, let's devide problem size to flops.

16!/16e10 = 130
17!/16e10 = 2223
18!/16e10 = 40014
19!/16e10 = 760281
20!/16e10 = 15205637 flops/ (flops/sec)

now, let's devide this with actual time taken it gives increasing rate for problem size,

16 - 130 / 0.65 = 200
17 - 2223 / 5 = 444
18 - 40014 / 34 = 1176
19 - 760281 / 265 = 2868
20 - 15205637 / 2042 = 7446 


so here increasing rate is = 2.5 .

now for 28 = 7446 * (2.5) ^ 8

so time = opp / rate
	= ((28!)/16e10) / 11361694
	= into year / (10) (for 160 cores)
	= 531 years 